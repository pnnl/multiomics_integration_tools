---
title: "MOFA"
author: "Flores, Javier E & Degnan, David J"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MOFA2)
library(tidyverse)
library(data.table)
library(kneedle) # devtools::install_github("etam4260/kneedle")
library(tidymodels)
library(fastshap)
library(shapviz)

seed = 2825
set.seed(seed)
theme_set(theme_bw())
```

## Make MOFA Object

Here, MOFA performs better when groups are not specified, as that mode looks for
variances within groups, where between is the goal here. 

```{r}
# Make the multiomics object
multiomics <- rbind(
  fread("../../Dataset/Scaled/16S_Edata.csv") %>%
    pivot_longer(2:ncol(.)) %>%
    mutate(view = "16S"),
  fread("../../Dataset/Scaled/Metabolomics_Negative.csv") %>%
    pivot_longer(2:ncol(.)) %>%
    mutate(view = "metabolomics negative"),
  fread("../../Dataset/Scaled/Metabolomics_Positive.csv") %>%
    pivot_longer(2:ncol(.)) %>%
    mutate(view = "metabolomics positive"),
  fread("../../Dataset/Scaled/Metaproteomics.csv") %>%
    pivot_longer(2:ncol(.)) %>%
    mutate(view = "metaproteomics")
) %>%
  rename(feature = Feature, sample = name) %>%
  mutate(
    group = as.factor("group") # Suggestion is to run without specifying groups 
  ) %>%
  select(sample, group, feature, view, value)

# Create the MOFA object
MOFAobject <- create_mofa(multiomics)
plot_data_overview(MOFAobject) 
```

```{r}
ggplot(multiomics, aes(x = value)) +
  geom_histogram(color = "black") +
  facet_wrap(.~view, scale = "free")
```

## Hyperparameter Selection

```{r}
#MOFAobject <- create_mofa(multiomics)
#
# Recommended to not provide group information
#mydataopts <- get_default_data_options(MOFAobject)
#
## Factors will be set each time. MOFA will remove any components it does not find informative. 
#mymodelopts <- get_default_model_options(MOFAobject)
#
## Use defaults
#mytrainopts <- get_default_training_options(MOFAobject)
#
##splits <- fdata %>%
##  select(sample, group) %>%
##  vfold_cv(v = 3, repeats = 5, strata = group)
##saveRDS(splits, "splits.RDS")
#
## Make and load splits once
#splits <- readRDS("splits.RDS")
#
## Extract split ids information
#split_ids <- lapply(splits$splits, function(x) {x$in_id})
#
## Get sample information
#sample_order <- fread("../../Dataset/Model_Ready/16S_Edata.csv") %>%
#  colnames() %>%
#  .[2:13]
#
## Write a function to calculate the ELBO value
#calc_ELBO <- function(spl_num, num_factors) {
#  
#  # Add number of components
#  mymodelopts$num_factors <- num_factors
#  
#  ######################
#  ## BUILD MOFA MODEL ##
#  ######################
#  
#  mofaname <- paste0("spl", spl_num, "_", "numfact", num_factors)
#  mofapath <- paste0("~/Downloads/MOFA_Mods/", mofaname, ".hdf5")
#  
#  # Train MOFA 
#  multiomics[multiomics$sample %in% sample_order[split_ids[[spl_num]]],] %>%
#    create_mofa() %>%
#    prepare_mofa(model_options = mymodelopts) %>%
#    run_mofa(use_basilisk = TRUE, outfile = mofapath)
#  
#  # Load data
#  trainedMOFA <- load_model(file = mofapath, remove_inactive_factors = FALSE)
#  return(trainedMOFA@training_stats$elbo %>% .[!is.na(.)] %>% max())
# 
#}
#
## Iterate through the number of elements and factors 
#tuning <- expand.grid(split = 1:15, num_com = 2:8) %>%
#  mutate(ELBO = map2_dbl(split, num_com, calc_ELBO))
#
#fwrite(tuning, "tuning.csv", quote = F, row.names = F)

MOFA_tuning <- fread("tuning.csv") %>%
  mutate(num_com = as.factor(num_com)) %>%
  rename(`Number of Components` = num_com) %>%
  ggplot(aes(x = `Number of Components`, y = ELBO)) +
    geom_boxplot() +
    geom_point() + 
    theme_bw()
ggsave("../../Plots/Supplemental_MOFATuning.png", dpi = 300)
MOFA_tuning
```

## Train MOFA

```{r}
## Let's run MOFA with all the centering and scaling options on
#mydataopts <- get_default_data_options(MOFAobject)
#
## Let's set the maximum number of factors to 8. MOFA will remove any components
## it does not find informative. 
#mymodelopts <- get_default_model_options(MOFAobject)
#mymodelopts$num_factors <- 5
#
## Prepare the MOFA Object
#MOFAobject <- prepare_mofa(object = MOFAobject,
#                           data_options = mydataopts,
#                           
#                           # We can make counts follow poisson, however it is well known
#                           # that transcriptomics data often violates the assumption of 
#                           # a poisson distribution
#                           model_options = mymodelopts, 
#                           
#                           training_options = get_default_training_options(MOFAobject))
#
## To get MOFA to run, I have to set basilisk to FALSE first, then have it fail, then run on TRUE
#MOFAobject.trained <- run_mofa(MOFAobject, outfile = "mofa.hdf5", use_basilisk = TRUE)

# Load trained object
MOFAobject.trained <- load_model("mofa.hdf5")
```

## Construct U Matrix

```{r}
u_mat <- get_factors(MOFAobject.trained, as.data.frame = T) %>%
  pivot_wider(id_cols = c(sample, group), names_from = factor) %>%
  mutate(
    group = c(rep("00wk", 3), rep("post-00wk", 9)),
    group = factor(group, levels = c("00wk", "post-00wk"))
  ) %>%
  select(-sample)
fwrite(u_mat, "../../Comparison/u_matrix/MOFA_umat.csv", quote = F, row.names = F)
u_mat
```

## Determine Top Factors

```{r}
# Let's build a neural net. First, let's define the engine.
mod_nn <- mlp(hidden_units = tune(),
              penalty = tune(),
              epochs = tune()) %>%
  parsnip::set_engine("nnet") %>%
  parsnip::set_mode("classification")

# Now let's define the grid
nn_grid <- grid_regular(hidden_units(),
                        penalty(),
                        epochs(),
                        levels = 3)

# Define model recipe 
tune_rec <- recipes::recipe(group ~ ., data = u_mat) 

# Define a resampling schema
resamp_data <- vfold_cv(u_mat,
                        v = 3, 
                        repeats = 5,
                        strata = group)

# Define workflow set
tune_wfs <- workflow_set(
  preproc = list("all" = tune_rec),
  models = list(nn = mod_nn)
)
wfid_names <- tune_wfs$wflow_id

#  Add tuning grid
tune_wfs <- tune_wfs %>%
  workflowsets::option_add(id = wfid_names[which(grepl("nn", wfid_names))], grid = nn_grid)

# Specify suite of test metrics
test_metrics <- metric_set(pr_auc)

# Run model
tune_wf_res <- tune_wfs %>%
  workflow_map(resamples = resamp_data,
               seed = seed,
               verbose = TRUE,
               metrics = test_metrics)

# Extract best parameters
best_mod_info <- tune_wf_res %>%
  extract_workflow_set_result(id = "all_nn") %>%
  select_best(metric = "pr_auc")

# Extract best model
fitted_best_mod <- tune_wf_res %>%
  extract_workflow(id = "all_nn") %>%
  finalize_workflow(best_mod_info) %>%
  fit(data = u_mat)
```

```{r}
tune_wf_res %>% collect_metrics() %>% filter(.metric == "pr_auc") %>% arrange(-mean)
```

## Calculate Shapley Values

```{r}
# Let's define a function for predicted probabilities
predict_prob <- function(model, newdata){
  stats::predict(model, newdata, type = "prob")$`.pred_00wk`
}

# Calculate shapley values
mod_shaps <- fastshap::explain(fitted_best_mod, 
                  X = subset(u_mat, select = -group), 
                  nsim = 10, 
                  pred_wrapper = predict_prob)

# Let's visualize the shapley values
mod_shaps_viz <- shapviz(mod_shaps, X = subset(u_mat, select = -group))
sv_importance(mod_shaps_viz, show_numbers = T) + 
  theme_bw() + 
  ggtitle("MOFA") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
# Take from the shapViz package 
.get_imp <- function(z, sort_features = TRUE) {
  if (is.matrix(z)) {
    imp <- colMeans(abs(z))
    if (sort_features) {
      imp <- sort(imp, decreasing = TRUE)
    }
    return(imp)
  }
  # list/mshapviz
  imp <- sapply(z, function(x) colMeans(abs(x)))
  if (sort_features) {
    imp <- imp[order(-rowSums(imp)), ]
  }
  return(imp)
}

.get_imp(get_shap_values(mod_shaps_viz)) %>%
  as.data.frame() %>%
  `colnames<-`(c("Mean Absolute SHAP Value")) %>%
  mutate(Factor = row.names(.)) %>%
  relocate(Factor) %>%
  fwrite("../../Comparison/SHAP_Value/MOFA_SHAP_Value.csv", quote = F, row.names = F)
```


## Construct V Matrix

```{r}
# Construct the V Matrix
v_mat <- do.call(rbind, lapply(1:4, function(num) {
  ds <- MOFA2::get_weights(MOFAobject.trained)[[num]] %>%
    data.frame() %>%
    mutate(Feature = row.names(.)) 
  ds$View <- names(MOFA2::get_weights(MOFAobject.trained))[num]
  return(ds)
})) %>% 
  pivot_longer(1:5) %>%
  rename(Factor = name, Weight = value) %>%
  select(Factor, Weight, Feature, View)

fwrite(v_mat, "../../Comparison/v_matrix/MOFA_vmat.csv", quote = F, row.names = F)

v_mat
```

## Detect Top Features with Kneedle

```{r}
kneedle_df <- v_mat %>%
  filter(Factor == "Factor1") %>%
  select(Weight, View, Feature) %>%
  mutate(`Absolute Weight` = abs(Weight)) %>%
  arrange(-`Absolute Weight`) %>%
  mutate(Rank = 1:nrow(.)) 

knee <- kneedle(kneedle_df$Rank, kneedle_df$`Absolute Weight`)

fwrite(kneedle_df %>% select(View, Feature, `Absolute Weight`, Rank), "../../Comparison/kneedle_df/MOFA_kneedle.csv", quote = F, row.names = F)

# Let's plot
ggplot(kneedle_df, aes(x = Rank, y = `Absolute Weight`, color = View)) +
  geom_point() +
  theme_bw() +
  geom_hline(yintercept = knee[2], linetype = "dashed") +
  ggtitle("MOFA") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "bottom")
```

```{r}
kneedle_df %>%
  filter(Rank <= knee[1]) %>%
  select(View, Feature, `Absolute Weight`, Rank) %>%
  fwrite("../../Comparison/TopK/MOFA_TopK.csv", quote = F, row.names = F)
```

```{r}
kneedle_df %>%
  filter(Rank <= knee[1]) %>%
  select(View, Feature, `Absolute Weight`, Rank)
```


